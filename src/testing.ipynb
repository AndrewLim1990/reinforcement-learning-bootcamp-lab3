{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting click\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/c1/8806f99713ddb993c5366c362b2f908f18269f8d792aff1abfd700775a77/click-6.7-py2.py3-none-any.whl (71kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 1.1MB/s ta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: click\n",
      "Successfully installed click-6.7\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "import time\n",
    "import chainer as C\n",
    "import chainer.functions as F\n",
    "import numpy as np\n",
    "import pickle\n",
    "import click\n",
    "import gym\n",
    "\n",
    "from simpledqn.replay_buffer import ReplayBuffer\n",
    "import logger\n",
    "from simpledqn.wrappers import NoopResetEnv, EpisodicLifeEnv\n",
    "\n",
    "nprs = np.random.RandomState\n",
    "\n",
    "\n",
    "def assert_allclose(a, b):\n",
    "    if isinstance(a, (np.ndarray, float, int)):\n",
    "        np.testing.assert_allclose(a, b)\n",
    "    elif isinstance(a, (tuple, list)):\n",
    "        assert isinstance(b, (tuple, list))\n",
    "        assert len(a) == len(b)\n",
    "        for a_i, b_i in zip(a, b):\n",
    "            assert_allclose(a_i, b_i)\n",
    "    elif isinstance(a, C.Variable):\n",
    "        assert isinstance(b, C.Variable)\n",
    "        assert_allclose(a.data, b.data)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "rng = nprs(42)\n",
    "\n",
    "\n",
    "# ---------------------\n",
    "\n",
    "class Adam(object):\n",
    "    def __init__(self, shape, stepsize, beta1=0.9, beta2=0.999, epsilon=1e-08):\n",
    "        self.stepsize, self.beta1, self.beta2, self.epsilon = stepsize, beta1, beta2, epsilon\n",
    "        self.t = 0\n",
    "        self.v = np.zeros(shape, dtype=np.float32)\n",
    "        self.m = np.zeros(shape, dtype=np.float32)\n",
    "\n",
    "    def step(self, g):\n",
    "        self.t += 1\n",
    "        a = self.stepsize * \\\n",
    "            np.sqrt(1 - self.beta2 ** self.t) / (1 - self.beta1 ** self.t)\n",
    "        self.v = self.beta2 * self.v + (1 - self.beta2) * (g * g)\n",
    "        self.m = self.beta1 * self.m + (1 - self.beta1) * g\n",
    "        step = - a * self.m / (np.sqrt(self.v) + self.epsilon)\n",
    "        return step\n",
    "\n",
    "\n",
    "# ---------------------\n",
    "\n",
    "class NN(object):\n",
    "    \"\"\"Simple transparent neural network (multilayer perceptron) model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dims=None, out_fn=None):\n",
    "        assert dims is not None\n",
    "        assert out_fn is not None\n",
    "        assert len(dims) >= 2\n",
    "\n",
    "        self._out_fn = out_fn\n",
    "        self.lst_w, self.lst_b = [], []\n",
    "        for i in range(len(dims) - 1):\n",
    "            shp = dims[i + 1], dims[i]\n",
    "            # Correctly init weights.\n",
    "            std = 0.01 if i == len(dims) - 2 else 1.0\n",
    "            out = rng.randn(*shp).astype(np.float32)\n",
    "            out *= std / np.sqrt(np.square(out).sum(axis=0, keepdims=True))\n",
    "            self.lst_w.append(C.Variable(out))\n",
    "            self.lst_b.append(C.Variable(np.zeros(shp[0], dtype=np.float32)))\n",
    "        self.train_vars = self.lst_w + self.lst_b\n",
    "\n",
    "    def set_params(self, params):\n",
    "        lst_wt, lst_bt = params\n",
    "        for w, wt in zip(self.lst_w, lst_wt):\n",
    "            w.data[...] = wt.data\n",
    "        for b, bt in zip(self.lst_b, lst_bt):\n",
    "            b.data[...] = bt.data\n",
    "\n",
    "    def get_params(self):\n",
    "        return self.lst_w, self.lst_b\n",
    "\n",
    "    def dump(self, file_path=None):\n",
    "        file = open(file_path, 'wb')\n",
    "        pickle.dump(dict(w=self.lst_w, b=self.lst_b), file, -1)\n",
    "        file.close()\n",
    "\n",
    "    def load(self, file_path=None):\n",
    "        file = open(file_path, 'rb')\n",
    "        params = pickle.load(file)\n",
    "        file.close()\n",
    "        return params['w'], params['b']\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, (w, b) in enumerate(zip(self.lst_w, self.lst_b)):\n",
    "            x = F.linear(x, w, b)\n",
    "            if i != len(self.lst_w) - 1:\n",
    "                x = F.tanh(x)\n",
    "            else:\n",
    "                return self._out_fn(x)\n",
    "\n",
    "\n",
    "# ---------------------\n",
    "\n",
    "def preprocess_obs_gridworld(obs):\n",
    "    return obs.astype(np.float32)\n",
    "\n",
    "\n",
    "def preprocess_obs_ram(obs):\n",
    "    return obs.astype(np.float32) / 255.\n",
    "\n",
    "\n",
    "class LinearSchedule(object):\n",
    "    def __init__(self, schedule_timesteps, final_p, initial_p):\n",
    "        self.schedule_timesteps = schedule_timesteps\n",
    "        self.final_p = final_p\n",
    "        self.initial_p = initial_p\n",
    "\n",
    "    def value(self, t):\n",
    "        fraction = min(1.0, float(t) / self.schedule_timesteps)\n",
    "        return self.initial_p + (self.final_p - self.initial_p) * fraction\n",
    "\n",
    "\n",
    "class DQN(object):\n",
    "    def __init__(self, env, get_obs_dim, get_act_dim, obs_preprocessor, replay_buffer, q_dim_hid,\n",
    "                 opt_batch_size, discount, initial_step, max_steps, learning_start_itr, target_q_update_freq,\n",
    "                 train_q_freq,\n",
    "                 log_freq, double_q, final_eps, initial_eps, fraction_eps, render):\n",
    "        self._env = env\n",
    "        self._get_obs_dim = get_obs_dim\n",
    "        self._get_act_dim = get_act_dim\n",
    "        self._obs_preprocessor = obs_preprocessor\n",
    "        self._replay_buffer = replay_buffer\n",
    "        self._initial_step = initial_step\n",
    "        self._max_steps = max_steps\n",
    "        self._target_q_update_freq = target_q_update_freq\n",
    "        self._learning_start_itr = learning_start_itr\n",
    "        self._train_q_freq = train_q_freq\n",
    "        self._log_freq = log_freq\n",
    "        self._double_q = double_q\n",
    "        self._act_dim = env.action_space.n\n",
    "        self._opt_batch_size = opt_batch_size\n",
    "        self._discount = discount\n",
    "        self._render = render\n",
    "        nn_args = dict(\n",
    "            dims=[self._get_obs_dim(env)] + q_dim_hid +\n",
    "            [self._get_act_dim(env)],\n",
    "            out_fn=lambda x: x)\n",
    "        # Q-function, Q(s,a,\\theta)\n",
    "        self._q = NN(**nn_args)\n",
    "        # Target Q-function, Q(s,a,\\theta')\n",
    "        self._qt = NN(**nn_args)\n",
    "        self.lst_adam = [Adam(var.shape, stepsize=1e-4)\n",
    "                         for var in self._q.train_vars]\n",
    "        self.exploration = LinearSchedule(\n",
    "            schedule_timesteps=int(fraction_eps * max_steps),\n",
    "            initial_p=initial_eps,\n",
    "            final_p=final_eps)\n",
    "\n",
    "    def eps_greedy(self, obs, epsilon):\n",
    "        # Check Q function, do argmax.\n",
    "        rnd = rng.rand()\n",
    "        if rnd > epsilon:\n",
    "            obs = self._obs_preprocessor(obs)\n",
    "            q_values = self._q.forward(obs)\n",
    "            return F.argmax(q_values, axis=1).data[0]\n",
    "        else:\n",
    "            return rng.randint(0, self._act_dim)\n",
    "\n",
    "\n",
    "    def compute_double_q_learning_loss(self, l_obs, l_act, l_rew, l_next_obs, l_done):\n",
    "        \"\"\"\n",
    "        :param l_obs: A chainer variable holding a list of observations. Should be of shape N * |S|.\n",
    "        :param l_act: A chainer variable holding a list of actions. Should be of shape N.\n",
    "        :param l_rew: A chainer variable holding a list of rewards. Should be of shape N.\n",
    "        :param l_next_obs: A chainer variable holding a list of observations at the next time step. Should be of\n",
    "        shape N * |S|.\n",
    "        :param l_done: A chainer variable holding a list of binary values (indicating whether episode ended after this\n",
    "        time step). Should be of shape N.\n",
    "        :return: A chainer variable holding a scalar loss.\n",
    "        \"\"\"\n",
    "        # Hint: You may want to make use of the following fields: self._discount, self._q, self._qt\n",
    "        # Hint2: Q-function can be called by self._q.forward(argument)\n",
    "        # Hint3: You might also find https://docs.chainer.org/en/stable/reference/generated/chainer.functions.select_item.html useful\n",
    "        loss = C.Variable(np.array([0.]))  # TODO: replace this line\n",
    "        \"*** YOUR CODE HERE ***\"\n",
    "        return loss\n",
    "\n",
    "    def train_q(self, l_obs, l_act, l_rew, l_next_obs, l_done):\n",
    "        \"\"\"Update Q-value function by sampling from the replay buffer.\"\"\"\n",
    "\n",
    "        l_obs = self._obs_preprocessor(l_obs)\n",
    "        l_next_obs = self._obs_preprocessor(l_next_obs)\n",
    "        if self._double_q:\n",
    "            loss = self.compute_double_q_learning_loss(\n",
    "                l_obs, l_act, l_rew, l_next_obs, l_done)\n",
    "        else:\n",
    "            loss = self.compute_q_learning_loss(\n",
    "                l_obs, l_act, l_rew, l_next_obs, l_done)\n",
    "        for var in self._q.train_vars:\n",
    "            var.cleargrad()\n",
    "        loss.backward()\n",
    "        for var, adam in zip(self._q.train_vars, self.lst_adam):\n",
    "            var.data += adam.step(var.grad)\n",
    "        return loss.data\n",
    "\n",
    "    def _update_target_q(self):\n",
    "        \"\"\"Update the target Q-value function by copying the current Q-value function weights.\"\"\"\n",
    "        q_params = self._q.get_params()\n",
    "        self._qt.set_params(q_params)\n",
    "\n",
    "    def train(self):\n",
    "        obs = self._env.reset()\n",
    "\n",
    "        episode_rewards = []\n",
    "        n_episodes = 0\n",
    "        l_episode_return = deque([], maxlen=10)\n",
    "        l_discounted_episode_return = deque([], maxlen=10)\n",
    "        l_tq_squared_error = deque(maxlen=50)\n",
    "        log_itr = -1\n",
    "        for itr in range(self._initial_step, self._max_steps):\n",
    "            act = self.eps_greedy(obs[np.newaxis, :],\n",
    "                                  self.exploration.value(itr))\n",
    "            next_obs, rew, done, _ = self._env.step(act)\n",
    "            if self._render:\n",
    "                self._env.render()\n",
    "            self._replay_buffer.add(obs, act, rew, next_obs, float(done))\n",
    "\n",
    "            episode_rewards.append(rew)\n",
    "\n",
    "            if done:\n",
    "                obs = self._env.reset()\n",
    "                episode_return = np.sum(episode_rewards)\n",
    "                discounted_episode_return = np.sum(\n",
    "                    episode_rewards * self._discount ** np.arange(len(episode_rewards)))\n",
    "                l_episode_return.append(episode_return)\n",
    "                l_discounted_episode_return.append(discounted_episode_return)\n",
    "                episode_rewards = []\n",
    "                n_episodes += 1\n",
    "            else:\n",
    "                obs = next_obs\n",
    "\n",
    "            if itr % self._target_q_update_freq == 0 and itr > self._learning_start_itr:\n",
    "                self._update_target_q()\n",
    "\n",
    "            if itr % self._train_q_freq == 0 and itr > self._learning_start_itr:\n",
    "                # Sample from replay buffer.\n",
    "                l_obs, l_act, l_rew, l_obs_prime, l_done = self._replay_buffer.sample(\n",
    "                    self._opt_batch_size)\n",
    "                # Train Q value function with sampled data.\n",
    "                td_squared_error = self.train_q(\n",
    "                    l_obs, l_act, l_rew, l_obs_prime, l_done)\n",
    "                l_tq_squared_error.append(td_squared_error)\n",
    "\n",
    "            if (itr + 1) % self._log_freq == 0 and len(l_episode_return) > 5:\n",
    "                log_itr += 1\n",
    "                logger.logkv('Iteration', log_itr)\n",
    "                logger.logkv('Steps', itr)\n",
    "                logger.logkv('Epsilon', self.exploration.value(itr))\n",
    "                logger.logkv('Episodes', n_episodes)\n",
    "                logger.logkv('AverageReturn', np.mean(l_episode_return))\n",
    "                logger.logkv('AverageDiscountedReturn',\n",
    "                             np.mean(l_discounted_episode_return))\n",
    "                logger.logkv('TDError^2', np.mean(l_tq_squared_error))\n",
    "                logger.dumpkvs()\n",
    "                self._q.dump(logger.get_dir() + '/weights.pkl')\n",
    "\n",
    "    def test(self, epsilon):\n",
    "        try:\n",
    "            self._q.set_params(self._q.load(logger.get_dir() + '/weights.pkl'))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        obs = self._env.reset()\n",
    "        while True:\n",
    "            act = self.eps_greedy(obs[np.newaxis, :], epsilon)\n",
    "            obs_prime, rew, done, _ = self._env.step(act)\n",
    "            self._env.render()\n",
    "            if done:\n",
    "                obs = self._env.reset()\n",
    "                print('Done!')\n",
    "                time.sleep(1)\n",
    "            else:\n",
    "                obs = obs_prime\n",
    "                \n",
    "    -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-08-06 17:33:50,757] Making new env: GridWorld-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| Iteration               | 0        |\n",
      "| Steps                   | 999      |\n",
      "| Epsilon                 | 0.90509  |\n",
      "| Episodes                | 58       |\n",
      "| AverageReturn           | 0        |\n",
      "| AverageDiscountedReturn | 0        |\n",
      "| TDError^2               | nan      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewlim/anaconda/envs/deeprlbootcamp/lib/python3.5/site-packages/numpy/core/fromnumeric.py:2909: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/andrewlim/anaconda/envs/deeprlbootcamp/lib/python3.5/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| Iteration               | 1        |\n",
      "| Steps                   | 1999     |\n",
      "| Epsilon                 | 0.8101   |\n",
      "| Episodes                | 110      |\n",
      "| AverageReturn           | 0.2      |\n",
      "| AverageDiscountedReturn | 0.16118  |\n",
      "| TDError^2               | 0.010432 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| Iteration               | 2         |\n",
      "| Steps                   | 2999      |\n",
      "| Epsilon                 | 0.7151    |\n",
      "| Episodes                | 164       |\n",
      "| AverageReturn           | 0.1       |\n",
      "| AverageDiscountedReturn | 0.094148  |\n",
      "| TDError^2               | 0.0084914 |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| Iteration               | 3         |\n",
      "| Steps                   | 3999      |\n",
      "| Epsilon                 | 0.6201    |\n",
      "| Episodes                | 225       |\n",
      "| AverageReturn           | 0         |\n",
      "| AverageDiscountedReturn | 0         |\n",
      "| TDError^2               | 0.0070759 |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| Iteration               | 4        |\n",
      "| Steps                   | 4999     |\n",
      "| Epsilon                 | 0.5251   |\n",
      "| Episodes                | 282      |\n",
      "| AverageReturn           | 0        |\n",
      "| AverageDiscountedReturn | 0        |\n",
      "| TDError^2               | 0.007314 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| Iteration               | 5         |\n",
      "| Steps                   | 5999      |\n",
      "| Epsilon                 | 0.4301    |\n",
      "| Episodes                | 339       |\n",
      "| AverageReturn           | 0.1       |\n",
      "| AverageDiscountedReturn | 0.087752  |\n",
      "| TDError^2               | 0.0022741 |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| Iteration               | 6         |\n",
      "| Steps                   | 6999      |\n",
      "| Epsilon                 | 0.3351    |\n",
      "| Episodes                | 391       |\n",
      "| AverageReturn           | 0         |\n",
      "| AverageDiscountedReturn | 0         |\n",
      "| TDError^2               | 0.0031528 |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| Iteration               | 7         |\n",
      "| Steps                   | 7999      |\n",
      "| Epsilon                 | 0.24009   |\n",
      "| Episodes                | 442       |\n",
      "| AverageReturn           | 0.1       |\n",
      "| AverageDiscountedReturn | 0.086006  |\n",
      "| TDError^2               | 0.0025752 |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| Iteration               | 8         |\n",
      "| Steps                   | 8999      |\n",
      "| Epsilon                 | 0.14509   |\n",
      "| Episodes                | 490       |\n",
      "| AverageReturn           | 0         |\n",
      "| AverageDiscountedReturn | 0         |\n",
      "| TDError^2               | 0.0038151 |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| Iteration               | 9         |\n",
      "| Steps                   | 9999      |\n",
      "| Epsilon                 | 0.050095  |\n",
      "| Episodes                | 523       |\n",
      "| AverageReturn           | 0         |\n",
      "| AverageDiscountedReturn | 0         |\n",
      "| TDError^2               | 0.0008946 |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| Iteration               | 10       |\n",
      "| Steps                   | 10999    |\n",
      "| Epsilon                 | 0.05     |\n",
      "| Episodes                | 552      |\n",
      "| AverageReturn           | 0        |\n",
      "| AverageDiscountedReturn | 0        |\n",
      "| TDError^2               | 0.002546 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| Iteration               | 11        |\n",
      "| Steps                   | 11999     |\n",
      "| Epsilon                 | 0.05      |\n",
      "| Episodes                | 581       |\n",
      "| AverageReturn           | 0         |\n",
      "| AverageDiscountedReturn | 0         |\n",
      "| TDError^2               | 0.0014306 |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| Iteration               | 12        |\n",
      "| Steps                   | 12999     |\n",
      "| Epsilon                 | 0.05      |\n",
      "| Episodes                | 610       |\n",
      "| AverageReturn           | 0         |\n",
      "| AverageDiscountedReturn | 0         |\n",
      "| TDError^2               | 0.0002274 |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 13         |\n",
      "| Steps                   | 13999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 636        |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 0.00097884 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 14         |\n",
      "| Steps                   | 14999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 667        |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 3.1796e-09 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 15         |\n",
      "| Steps                   | 15999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 699        |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 2.4042e-09 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 16         |\n",
      "| Steps                   | 16999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 730        |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 0.00019132 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 17         |\n",
      "| Steps                   | 17999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 760        |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 0.00019034 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 18         |\n",
      "| Steps                   | 18999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 785        |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 1.0047e-09 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 19         |\n",
      "| Steps                   | 19999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 817        |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 1.6532e-09 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 20         |\n",
      "| Steps                   | 20999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 842        |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 2.2847e-09 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 21         |\n",
      "| Steps                   | 21999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 889        |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 0.00018821 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 22         |\n",
      "| Steps                   | 22999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 951        |\n",
      "| AverageReturn           | 0.1        |\n",
      "| AverageDiscountedReturn | 0.072498   |\n",
      "| TDError^2               | 0.00018766 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 23         |\n",
      "| Steps                   | 23999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 981        |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 0.00018585 |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| Iteration               | 24         |\n",
      "| Steps                   | 24999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 1010       |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 0.00018397 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 25         |\n",
      "| Steps                   | 25999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 1038       |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 1.4746e-09 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 26         |\n",
      "| Steps                   | 26999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 1069       |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 4.1996e-09 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 27         |\n",
      "| Steps                   | 27999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 1101       |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 4.8056e-09 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 28         |\n",
      "| Steps                   | 28999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 1130       |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 0.00017972 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 29         |\n",
      "| Steps                   | 29999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 1157       |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 3.3827e-09 |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| Iteration               | 30        |\n",
      "| Steps                   | 30999     |\n",
      "| Epsilon                 | 0.05      |\n",
      "| Episodes                | 1189      |\n",
      "| AverageReturn           | 0         |\n",
      "| AverageDiscountedReturn | 0         |\n",
      "| TDError^2               | 3.381e-09 |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 31         |\n",
      "| Steps                   | 31999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 1219       |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 0.00017618 |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| Iteration               | 32        |\n",
      "| Steps                   | 32999     |\n",
      "| Epsilon                 | 0.05      |\n",
      "| Episodes                | 1250      |\n",
      "| AverageReturn           | 0         |\n",
      "| AverageDiscountedReturn | 0         |\n",
      "| TDError^2               | 1.278e-09 |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 33         |\n",
      "| Steps                   | 33999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 1276       |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 5.2142e-11 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 34         |\n",
      "| Steps                   | 34999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 1306       |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 3.3636e-11 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 35         |\n",
      "| Steps                   | 35999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 1336       |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 2.4564e-11 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 36         |\n",
      "| Steps                   | 36999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 1366       |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 2.1563e-11 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 37         |\n",
      "| Steps                   | 37999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 1397       |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 1.2805e-11 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 38         |\n",
      "| Steps                   | 38999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 1427       |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 2.6332e-11 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 39         |\n",
      "| Steps                   | 39999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 1459       |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 1.6114e-11 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 40         |\n",
      "| Steps                   | 40999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 1487       |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 1.1578e-11 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 41         |\n",
      "| Steps                   | 41999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 1516       |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 1.8093e-11 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 42         |\n",
      "| Steps                   | 42999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 1547       |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 6.6906e-10 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 43         |\n",
      "| Steps                   | 43999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 1578       |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 3.8016e-12 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 44         |\n",
      "| Steps                   | 44999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 1610       |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 1.8814e-11 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 45         |\n",
      "| Steps                   | 45999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 1639       |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 9.1491e-12 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 46         |\n",
      "| Steps                   | 46999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 1667       |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 4.9696e-12 |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| Iteration               | 47         |\n",
      "| Steps                   | 47999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 1695       |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 1.3487e-09 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 48         |\n",
      "| Steps                   | 48999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 1728       |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 1.4839e-11 |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| Iteration               | 49       |\n",
      "| Steps                   | 49999    |\n",
      "| Epsilon                 | 0.05     |\n",
      "| Episodes                | 1760     |\n",
      "| AverageReturn           | 0        |\n",
      "| AverageDiscountedReturn | 0        |\n",
      "| TDError^2               | 2.37e-10 |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 50         |\n",
      "| Steps                   | 50999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 1794       |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 2.2261e-10 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 51         |\n",
      "| Steps                   | 51999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 1825       |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 5.1236e-10 |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| Iteration               | 52        |\n",
      "| Steps                   | 52999     |\n",
      "| Epsilon                 | 0.05      |\n",
      "| Episodes                | 1855      |\n",
      "| AverageReturn           | 0         |\n",
      "| AverageDiscountedReturn | 0         |\n",
      "| TDError^2               | 3.601e-12 |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 53         |\n",
      "| Steps                   | 53999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 1886       |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 1.5425e-11 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 54         |\n",
      "| Steps                   | 54999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 1917       |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 5.4536e-11 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 55         |\n",
      "| Steps                   | 55999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 1948       |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 3.3036e-11 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 56         |\n",
      "| Steps                   | 56999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 1981       |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 2.5625e-10 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 57         |\n",
      "| Steps                   | 57999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 2010       |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 6.4227e-11 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 58         |\n",
      "| Steps                   | 58999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 2047       |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 2.5647e-10 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 59         |\n",
      "| Steps                   | 59999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 2078       |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 5.0735e-10 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 60         |\n",
      "| Steps                   | 60999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 2110       |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 1.1978e-11 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 61         |\n",
      "| Steps                   | 61999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 2140       |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 2.1466e-11 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 62         |\n",
      "| Steps                   | 62999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 2167       |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 3.0256e-12 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 63         |\n",
      "| Steps                   | 63999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 2203       |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 1.1124e-10 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 64         |\n",
      "| Steps                   | 64999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 2235       |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 5.0872e-11 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 65         |\n",
      "| Steps                   | 65999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 2268       |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 3.7291e-12 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 66         |\n",
      "| Steps                   | 66999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 2297       |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 2.3419e-10 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 67         |\n",
      "| Steps                   | 67999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 2326       |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 3.9745e-11 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 68         |\n",
      "| Steps                   | 68999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 2357       |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 2.4752e-10 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| Iteration               | 69         |\n",
      "| Steps                   | 69999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 2388       |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 1.1452e-10 |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| Iteration               | 70         |\n",
      "| Steps                   | 70999      |\n",
      "| Epsilon                 | 0.05       |\n",
      "| Episodes                | 2416       |\n",
      "| AverageReturn           | 0          |\n",
      "| AverageDiscountedReturn | 0          |\n",
      "| TDError^2               | 0.00016566 |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-326dc7a14445>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;31m# Train the agent!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;31m# Close gym environment.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-73-0577de065b3c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m                 \u001b[0;31m# Sample from replay buffer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                 l_obs, l_act, l_rew, l_obs_prime, l_done = self._replay_buffer.sample(\n\u001b[0;32m--> 253\u001b[0;31m                     self._opt_batch_size)\n\u001b[0m\u001b[1;32m    254\u001b[0m                 \u001b[0;31m# Train Q value function with sampled data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                 td_squared_error = self.train_q(\n",
      "\u001b[0;32m~/projects/reinforcement_learning/lab3/src/simpledqn/replay_buffer.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     69\u001b[0m         idxes = [random.randint(0, len(self._buffer) - 1)\n\u001b[1;32m     70\u001b[0m                  for _ in range(batch_size)]\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encode_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/reinforcement_learning/lab3/src/simpledqn/replay_buffer.py\u001b[0m in \u001b[0;36m_encode_sample\u001b[0;34m(self, idxes)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mrewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mobses_tp1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_tp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0mdones\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobses_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobses_tp1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdones\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env_id = 'GridWorld-v0'\n",
    "double = False\n",
    "render = False\n",
    "\n",
    "if env_id == 'GridWorld-v0':\n",
    "    from simpledqn import gridworld_env\n",
    "    env = gym.make('GridWorld-v0')\n",
    "\n",
    "    def get_obs_dim(x): return x.observation_space.n\n",
    "\n",
    "    def get_act_dim(x): return x.action_space.n\n",
    "    obs_preprocessor = preprocess_obs_gridworld\n",
    "    max_steps = 100000\n",
    "    log_freq = 1000\n",
    "    target_q_update_freq = 100\n",
    "    initial_step = 0\n",
    "    log_dir = \"data/local/dqn_gridworld\"\n",
    "\n",
    "logger.session(log_dir).__enter__()\n",
    "env.seed(42)\n",
    "\n",
    "# Initialize the replay buffer that we will use.\n",
    "replay_buffer = ReplayBuffer(max_size=10000)\n",
    "\n",
    "# Initialize DQN training procedure.\n",
    "dqn = DQN(\n",
    "    env=env,\n",
    "    get_obs_dim=get_obs_dim,\n",
    "    get_act_dim=get_act_dim,\n",
    "    obs_preprocessor=obs_preprocessor,\n",
    "    replay_buffer=replay_buffer,\n",
    "\n",
    "    # Q-value parameters\n",
    "    q_dim_hid=[256, 256] if env_id == 'Pong-ram-v0' else [],\n",
    "    opt_batch_size=64,\n",
    "\n",
    "    # DQN gamma parameter\n",
    "    discount=0.99,\n",
    "\n",
    "    # Training procedure length\n",
    "    initial_step=initial_step,\n",
    "    max_steps=max_steps,\n",
    "    learning_start_itr=max_steps // 100,\n",
    "    # Frequency of copying the actual Q to the target Q\n",
    "    target_q_update_freq=target_q_update_freq,\n",
    "    # Frequency of updating the Q-value function\n",
    "    train_q_freq=4,\n",
    "    # Double Q\n",
    "    double_q=double,\n",
    "\n",
    "    # Exploration parameters\n",
    "    initial_eps=1.0,\n",
    "    final_eps=0.05,\n",
    "    fraction_eps=0.1,\n",
    "\n",
    "    # Logging\n",
    "    log_freq=log_freq,\n",
    "    render=render,\n",
    ")\n",
    "\n",
    "if env_id == 'GridWorld-v0':\n",
    "    # Run tests on GridWorld-v0\n",
    "    test_args = dict(\n",
    "        l_obs=nprs(0).rand(64, 16).astype(np.float32),\n",
    "        l_act=nprs(1).randint(0, 3, size=(64,)),\n",
    "        l_rew=nprs(2).randint(0, 3, size=(64,)).astype(np.float32),\n",
    "        l_next_obs=nprs(3).rand(64, 16).astype(np.float32),\n",
    "        l_done=nprs(4).randint(0, 2, size=(64,)).astype(np.float32),\n",
    "    )\n",
    "    if not double:\n",
    "        tgt = np.array([1.909377098083496], dtype=np.float32)\n",
    "        actual_var = dqn.compute_q_learning_loss(**test_args)\n",
    "        test_name = \"compute_q_learning_loss\"\n",
    "        assert isinstance(\n",
    "            actual_var, C.Variable), \"%s should return a Chainer variable\" % test_name\n",
    "        actual = actual_var.data\n",
    "        try:\n",
    "            assert_allclose(tgt, actual)\n",
    "            print(\"Test for %s passed!\" % test_name)\n",
    "        except AssertionError as e:\n",
    "            pass\n",
    "#             print(\"Warning: test for %s didn't pass!\" % test_name)\n",
    "#             print(e)\n",
    "#             input(\n",
    "#                 \"** Test failed. Press Ctrl+C to exit or press enter to continue training anyways\")\n",
    "    else:\n",
    "        tgt = np.array([1.9066928625106812], dtype=np.float32)\n",
    "        actual_var = dqn.compute_double_q_learning_loss(**test_args)\n",
    "        test_name = \"compute_double_q_learning_loss\"\n",
    "        assert isinstance(\n",
    "            actual_var, C.Variable), \"%s should return a Chainer variable\" % test_name\n",
    "        actual = actual_var.data\n",
    "        try:\n",
    "            assert_allclose(tgt, actual)\n",
    "            print(\"Test for %s passed!\" % test_name)\n",
    "        except AssertionError as e:\n",
    "            print(\"Warning: test for %s didn't pass!\" % test_name)\n",
    "            print(e)\n",
    "            input(\n",
    "                \"** Test failed. Press Ctrl+C to exit or press enter to continue training anyways\")\n",
    "\n",
    "if render:\n",
    "    dqn.test(epsilon=0.0)\n",
    "else:\n",
    "    # Train the agent!\n",
    "    dqn.train()\n",
    "\n",
    "# Close gym environment.\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  5.], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[0, 1, 2], [3, 4, 5]], np.float32)\n",
    "t = np.array([0, 2], np.int32)\n",
    "y = F.select_item(x, t)\n",
    "y.shape\n",
    "# (2,)\n",
    "y.data\n",
    "# array([0., 5.], dtype=float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
